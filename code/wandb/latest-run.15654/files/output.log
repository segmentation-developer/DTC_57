
Namespace(D_lr=0.0001, base_lr=0.01, batch_size=4, beta=0.3, consistency=1.0, consistency_rampup=40.0, consistency_type='kl', consistency_weight=0.1, deterministic=1, ema_decay=0.99, exp='LA/SSL_DTC_VNetandUnetr', gamma=0.5, gpu='4,5,6,7', labeled_bs=2, labelnum=16, max_iterations=6000, root_path='/data/sohui/LA_dataset/2018LA_Seg_TrainingSet', seed=1340, with_cons='without_cons')
total 80 samples
8 itertations per epoch
  0%|                                         | 0/751 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "/home/sohui/code/DTC/code/SSL_train_la_dtc_VNetandUnet.py", line 250, in <module>
    loss.backward()
  File "/home/sohui/anaconda3/envs/unetr/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/sohui/anaconda3/envs/unetr/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 246.00 MiB (GPU 0; 10.92 GiB total capacity; 9.65 GiB already allocated; 63.44 MiB free; 10.11 GiB reserved in total by PyTorch)