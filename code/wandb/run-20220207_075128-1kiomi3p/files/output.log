
Namespace(D_lr=0.0001, base_lr=0.004, batch_size=4, beta=0.3, consistency=1.0, consistency_rampup=40.0, consistency_type='kl', consistency_weight=0.1, deterministic=1, ema_decay=0.99, exp='LA/SSL_DTC_VNet_dilation_concat', gamma=0.5, gpu='1', labeled_bs=2, labelnum=16, max_iterations=6000, root_path='/data/sohui/LA_dataset/2018LA_Seg_TrainingSet', seed=1337, with_cons='without_cons')
  0%|                                         | 0/751 [00:00<?, ?it/s]
total 80 samples
8 itertations per epoch
iteration 1 : loss : 1.516347, loss_dice: 0.623883
iteration 1 : loss : 1.516347
iteration 2 : loss : 1.536334, loss_dice: 0.627480
iteration 2 : loss : 1.536334
iteration 3 : loss : 1.544619, loss_dice: 0.685707
iteration 3 : loss : 1.544619
iteration 4 : loss : 1.438816, loss_dice: 0.556318
iteration 4 : loss : 1.438816
iteration 5 : loss : 1.397746, loss_dice: 0.574919
iteration 5 : loss : 1.397746
iteration 6 : loss : 1.322680, loss_dice: 0.471096

  0%|                               | 1/751 [00:19<4:01:31, 19.32s/it]
iteration 7 : loss : 1.286284, loss_dice: 0.548965
iteration 7 : loss : 1.286284
iteration 8 : loss : 1.281996, loss_dice: 0.559393
iteration 8 : loss : 1.281996
iteration 9 : loss : 1.359417, loss_dice: 0.609947
iteration 9 : loss : 1.359417
iteration 10 : loss : 1.247114, loss_dice: 0.540263
iteration 10 : loss : 1.247114
iteration 11 : loss : 1.285085, loss_dice: 0.549178
iteration 11 : loss : 1.285085
iteration 12 : loss : 1.348763, loss_dice: 0.570287
iteration 12 : loss : 1.348763
iteration 13 : loss : 1.246535, loss_dice: 0.498375
iteration 13 : loss : 1.246535
iteration 14 : loss : 1.409440, loss_dice: 0.625563
iteration 14 : loss : 1.409440
iteration 15 : loss : 1.275270, loss_dice: 0.611315

  0%|                               | 2/751 [00:36<3:54:53, 18.82s/it]
iteration 16 : loss : 1.166482, loss_dice: 0.536229
iteration 16 : loss : 1.166482
iteration 17 : loss : 1.253879, loss_dice: 0.624911
iteration 17 : loss : 1.253879
iteration 18 : loss : 1.196385, loss_dice: 0.628501
iteration 18 : loss : 1.196385
iteration 19 : loss : 1.064795, loss_dice: 0.481557
iteration 19 : loss : 1.064795
iteration 20 : loss : 1.039387, loss_dice: 0.436911
iteration 20 : loss : 1.039387
iteration 21 : loss : 1.166993, loss_dice: 0.515457
iteration 21 : loss : 1.166993
iteration 22 : loss : 1.042987, loss_dice: 0.478703
iteration 22 : loss : 1.042987
iteration 23 : loss : 1.164219, loss_dice: 0.535074

  0%|                               | 3/751 [00:53<3:47:27, 18.25s/it]
iteration 24 : loss : 0.899997, loss_dice: 0.359445
iteration 24 : loss : 0.899997
iteration 25 : loss : 1.037686, loss_dice: 0.429408
iteration 25 : loss : 1.037686
iteration 26 : loss : 1.155172, loss_dice: 0.507381
iteration 26 : loss : 1.155172
iteration 27 : loss : 1.024545, loss_dice: 0.435212
iteration 27 : loss : 1.024545
iteration 28 : loss : 1.025945, loss_dice: 0.476016
iteration 28 : loss : 1.025945
iteration 29 : loss : 1.035117, loss_dice: 0.523251
iteration 29 : loss : 1.035117
iteration 30 : loss : 1.073566, loss_dice: 0.503399
iteration 30 : loss : 1.073566
iteration 31 : loss : 1.080047, loss_dice: 0.527878

  1%|▏                              | 4/751 [01:08<3:32:36, 17.08s/it]
iteration 32 : loss : 0.981544, loss_dice: 0.548833
iteration 32 : loss : 0.981544
iteration 33 : loss : 0.852937, loss_dice: 0.328946
iteration 33 : loss : 0.852937
iteration 34 : loss : 0.886243, loss_dice: 0.400597
iteration 34 : loss : 0.886243
iteration 35 : loss : 0.984603, loss_dice: 0.457720
iteration 35 : loss : 0.984603
iteration 36 : loss : 0.915967, loss_dice: 0.452897
iteration 36 : loss : 0.915967
iteration 37 : loss : 0.989208, loss_dice: 0.457972
iteration 37 : loss : 0.989208
iteration 38 : loss : 0.959766, loss_dice: 0.445217
iteration 38 : loss : 0.959766
iteration 39 : loss : 1.059426, loss_dice: 0.532171

  1%|▏                              | 5/751 [01:22<3:23:18, 16.35s/it]
iteration 40 : loss : 0.957258, loss_dice: 0.545443
iteration 40 : loss : 0.957258
iteration 41 : loss : 1.038844, loss_dice: 0.554716
iteration 41 : loss : 1.038844
iteration 42 : loss : 0.915316, loss_dice: 0.442981
iteration 42 : loss : 0.915316
iteration 43 : loss : 0.923986, loss_dice: 0.431238
iteration 43 : loss : 0.923986
iteration 44 : loss : 1.003894, loss_dice: 0.544447
iteration 44 : loss : 1.003894
iteration 45 : loss : 0.995068, loss_dice: 0.511507
iteration 45 : loss : 0.995068
iteration 46 : loss : 0.891957, loss_dice: 0.459707
iteration 46 : loss : 0.891957
iteration 47 : loss : 0.867086, loss_dice: 0.425989

  1%|▏                              | 6/751 [01:39<3:25:01, 16.51s/it]
iteration 48 : loss : 0.762024, loss_dice: 0.288430
iteration 48 : loss : 0.762024
iteration 49 : loss : 0.843585, loss_dice: 0.415745
  1%|▏                              | 6/751 [01:44<3:37:07, 17.49s/it]
Traceback (most recent call last):
  File "/home/sohui/code/DTC/code/SSL_train_la_dtc_VNet.py", line 204, in <module>
    gt_dis = compute_sdf(label_batch[:].cpu(
  File "/home/sohui/code/DTC/code/utils/util.py", line 142, in compute_sdf
    negdis = distance(negmask)
  File "/home/sohui/anaconda3/envs/unetr/lib/python3.8/site-packages/scipy/ndimage/morphology.py", line 2278, in distance_transform_edt
    _nd_image.euclidean_feature_transform(input, sampling, ft)
KeyboardInterrupt
iteration 50 : loss : 0.926530, loss_dice: 0.456402
iteration 50 : loss : 0.926530